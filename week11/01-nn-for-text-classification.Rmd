---
title: "Neural networks for text classification"
date: "25 March 2024"
output: html_document
---

--------------------------------------------------------------------------------

#### Preliminary notes

To install `keras` and run the notebooks from this week:

1. Run `install.packages("keras")`
2. Load the package with `library("keras")`
3. Then run the function `install_keras()` in the R-console

Afterwards the code in this notebook should run properly.

For more information on `tensorflow` (the basis of `keras`) see: https://tensorflow.rstudio.com/install/index.html

For issues resulting from already existing Python installations, the following can be helpful: https://tensorflow.rstudio.com/install/custom

--------------------------------------------------------------------------------

The following code example is taken from https://github.com/rstudio/keras/blob/01a2b5205562dfd58dcde5bea399b26c72b49b1b/vignettes/examples/reuters_mlp.R. It briefly illustrates how easily neural networks for tasks like text classification can be set up and trained through high-level libraries such as `keras`.

```{r}
library(keras)
```

Processing the data:

```{r}
# Considering only the max_words most frequent words
max_words <- 1000

# Loading data
reuters <- dataset_reuters(num_words = max_words, test_split = 0.2)
x_train <- reuters$train$x
y_train <- reuters$train$y
x_test <- reuters$test$x
y_test <- reuters$test$y

cat(length(x_train), "train sequences\n")
cat(length(x_test), "test sequences\n")

num_classes <- max(y_train) + 1 # +1 because y labels start at 0
cat(num_classes, "labels\n")


# Transform text into relative frequency matrix (mode = "count" would create dfm)
tokenizer <- text_tokenizer(num_words = max_words)
x_train <- sequences_to_matrix(tokenizer, x_train, mode = "freq")
x_test <- sequences_to_matrix(tokenizer, x_test, mode = "freq")

cat("x_train shape:", dim(x_train), "\n")
cat("x_test shape:", dim(x_test), "\n")

# Create one-hot labels
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
cat("y_train shape:", dim(y_train), "\n")
cat("y_test shape:", dim(y_test), "\n")
```

Creating the model:

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 512, input_shape = c(max_words)) %>% 
  layer_activation(activation = "relu") %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes) %>% 
  layer_activation(activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adam(learning_rate = 0.01),
  metrics = c("accuracy")
)
model
```

Training:

```{r}
batch_size <- 256
epochs <- 15

history <- model %>% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  verbose = 1,
  validation_split = 0.1,
)
```

Test set accuracy:

```{r}
score <- model %>% evaluate(
  x_test, y_test,
  batch_size = batch_size,
  verbose = 1
)

cat("Test loss:", score[[1]], "\n")
cat("Test accuracy", score[[2]], "\n")
```

References:

- https://github.com/rstudio/keras/blob/01a2b5205562dfd58dcde5bea399b26c72b49b1b/vignettes/examples/reuters_mlp.R
